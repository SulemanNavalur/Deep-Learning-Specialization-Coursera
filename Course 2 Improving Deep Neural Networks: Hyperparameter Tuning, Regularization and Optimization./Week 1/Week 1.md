# Week 1

Course 2 of Deep Learning Specialization Coursera.

Course - Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization.

Week 1
 
In Week 1, we will Discover and experiment with a variety of different initialization methods, apply L2 regularization and dropout to avoid 
model overfitting, then apply gradient checking to identify errors in a fraud detection model.

## Learning Objectives

* Give examples of how different types of initializations can lead to different results.
* Examine the importance of initialization in complex neural networks.
* Explain the difference between train/dev/test sets.
* Diagnose the bias and variance issues in your model.
* Assess the right time and place for using regularization methods such as dropout or L2 regularization.
* Explain Vanishing and Exploding gradients and how to deal with them.
* Use gradient checking to verify the accuracy of your backpropagation implementation.
* Apply zeros initialization, random initialization, and He initialization.
* Apply regularization to a deep learning model.

## Content

In Week 1 we get to see,
 
* Setting up your Machine Learning Application.
* Regularizing your Neural Network.
* Setting up your Optimization Problem.

## Practice Quiz

One Practice Quiz's,

* Aspects of Deep Learning.

## Practice Lab

Two Graded programming assignment,

* Regularization.
* Gradient Checking.
