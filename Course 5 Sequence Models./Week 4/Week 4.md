# Week 4

Course 5 of Deep Learning Specialization Coursera.

Course - Sequence Models.

Week 4
 
## Learning Objectives

* Create positional encodings to capture sequential relationships in data.
* Calculate scaled dot-product self-attention with word embeddings.
* Implement masked multi-head attention.
* Build and train a Transformer model.
* Fine-tune a pre-trained transformer model for Named Entity Recognition.
* Fine-tune a pre-trained transformer model for Question Answering.
* Implement a QA model in TensorFlow and PyTorch.
* Fine-tune a pre-trained transformer model to a custom dataset.
* Perform extractive Question Answering.

## Content

In Week 4 we get to see,
 
* Transformers.

## Practice Quiz

One Practice Quiz's,

* Transformers.

## Practice Lab

One Graded programming assignment,

* Transformers Architecture with TensorFlow.

## Optional Labs

Three Graded programming assignment,

* Transformers Pre-processing.
* Transformers Network Application: Named-Entity Recognition.
* Transformers Network Application: Question Answering.
